{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2830743, 79)\n"
     ]
    }
   ],
   "source": [
    "filenames = ['MachineLearningCSV/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv', 'MachineLearningCSV/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv', 'MachineLearningCSV/Friday-WorkingHours-Morning.pcap_ISCX.csv', 'MachineLearningCSV/Monday-WorkingHours.pcap_ISCX.csv','MachineLearningCSV/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv', 'MachineLearningCSV/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv', 'MachineLearningCSV/Tuesday-WorkingHours.pcap_ISCX.csv', 'MachineLearningCSV/Wednesday-workingHours.pcap_ISCX.csv']\n",
    "df_aug = pd.read_csv(filenames[0])\n",
    "for name in filenames[1:]:\n",
    "  df = pd.read_csv(name)\n",
    "  df_aug = pd.concat([df_aug, df], axis=0)\n",
    "  \n",
    "print(df_aug.shape)\n",
    "df_aug.to_csv('IDS-2017-full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_df(x, corr_val):\n",
    "    '''\n",
    "    Obj: Drops features that are strongly correlated to other features.\n",
    "          This lowers model complexity, and aids in generalizing the model.\n",
    "    Inputs:\n",
    "          df: features df (x)\n",
    "          corr_val: Columns are dropped relative to the corr_val input (e.g. 0.8)\n",
    "    Output: df that only includes uncorrelated features\n",
    "    '''\n",
    "\n",
    "    # Creates Correlation Matrix and Instantiates\n",
    "    corr_matrix = x.corr()\n",
    "    print(corr_matrix.shape)\n",
    "    print(len(corr_matrix.columns))\n",
    "    iters = range(len(corr_matrix.columns) -1 )\n",
    "    drop_cols = []\n",
    "\n",
    "    # Iterates through Correlation Matrix Table to find correlated columns\n",
    "    for i in iters:\n",
    "        for j in range(i):\n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = item.values\n",
    "            if abs(val) >= corr_val:\n",
    "                # Prints the correlated feature set and the corr val\n",
    "                print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n",
    "                drop_cols.append(col.values[0])\n",
    "                \n",
    "    \n",
    "\n",
    "    drop_cols = set(drop_cols)\n",
    "    print(drop_cols)\n",
    "    cols = [col for col in x.columns if col not in drop_cols]\n",
    "    \n",
    "    #no_drops = [i for i in range(len(corr_matrix.columns)) if i not in drops]\n",
    "    # Drops the correlated columns\n",
    "    #for i in drops:\n",
    "    #    col = x.iloc[:, (i+1):(i+2)].columns.values\n",
    "    #    x = x.drop(col, axis=1)\n",
    "   # return x\n",
    "    return x[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data ...\n",
      "Reading done\n",
      "(2830743, 78)\n",
      "Splitting ...\n",
      "Spliiting done.\n",
      "(1896597, 78)\n",
      "(934146, 78)\n",
      "(1896597,)\n",
      "(934146,)\n",
      "Correlated feature elimination\n",
      "(78, 78)\n",
      "78\n",
      " SYN Flag Count | Fwd PSH Flags | 1.0\n",
      " CWE Flag Count |  Fwd URG Flags | 1.0\n",
      " Avg Fwd Segment Size |  Fwd Packet Length Mean | 1.0\n",
      " Avg Bwd Segment Size |  Bwd Packet Length Mean | 1.0\n",
      " Fwd Header Length.1 |  Fwd Header Length | 1.0\n",
      "Subflow Fwd Packets |  Total Fwd Packets | 1.0\n",
      " Subflow Bwd Packets |  Total Backward Packets | 1.0\n",
      "{' SYN Flag Count', ' Fwd Header Length.1', ' Subflow Bwd Packets', 'Subflow Fwd Packets', ' Avg Bwd Segment Size', ' CWE Flag Count', ' Avg Fwd Segment Size'}\n",
      "Index([' Destination Port', ' Flow Duration', ' Total Fwd Packets',\n",
      "       ' Total Backward Packets', 'Total Length of Fwd Packets',\n",
      "       ' Total Length of Bwd Packets', ' Fwd Packet Length Max',\n",
      "       ' Fwd Packet Length Min', ' Fwd Packet Length Mean',\n",
      "       ' Fwd Packet Length Std', 'Bwd Packet Length Max',\n",
      "       ' Bwd Packet Length Min', ' Bwd Packet Length Mean',\n",
      "       ' Bwd Packet Length Std', 'Flow Bytes/s', ' Flow Packets/s',\n",
      "       ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max', ' Flow IAT Min',\n",
      "       'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max',\n",
      "       ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean', ' Bwd IAT Std',\n",
      "       ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags', ' Bwd PSH Flags',\n",
      "       ' Fwd URG Flags', ' Bwd URG Flags', ' Fwd Header Length',\n",
      "       ' Bwd Header Length', 'Fwd Packets/s', ' Bwd Packets/s',\n",
      "       ' Min Packet Length', ' Max Packet Length', ' Packet Length Mean',\n",
      "       ' Packet Length Std', ' Packet Length Variance', 'FIN Flag Count',\n",
      "       ' RST Flag Count', ' PSH Flag Count', ' ACK Flag Count',\n",
      "       ' URG Flag Count', ' ECE Flag Count', ' Down/Up Ratio',\n",
      "       ' Average Packet Size', 'Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk',\n",
      "       ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk', ' Bwd Avg Packets/Bulk',\n",
      "       'Bwd Avg Bulk Rate', ' Subflow Fwd Bytes', ' Subflow Bwd Bytes',\n",
      "       'Init_Win_bytes_forward', ' Init_Win_bytes_backward',\n",
      "       ' act_data_pkt_fwd', ' min_seg_size_forward', 'Active Mean',\n",
      "       ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std',\n",
      "       ' Idle Max', ' Idle Min'],\n",
      "      dtype='object')\n",
      "(1896597, 71)\n",
      "(934146, 71)\n",
      "(1896597,)\n",
      "(934146,)\n"
     ]
    }
   ],
   "source": [
    "#Read\n",
    "print('Reading data ...')\n",
    "df = pd.read_csv('IDS-2017-full.csv',)\n",
    "print('Reading done')\n",
    "\n",
    "RANDOM_SEED = 41\n",
    "\n",
    "le = LabelEncoder()\n",
    "df[' Label'] = le.fit_transform(df[' Label'])\n",
    "\n",
    "Y = df[' Label']\n",
    "X = df.drop([' Label'], axis=1)\n",
    "\n",
    "del df\n",
    "X=X.astype('float64')\n",
    "print(X.select_dtypes('float64').shape)\n",
    "\n",
    "#Replace inf values (with NaN ?)\n",
    "X=X.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "#Fill NaN\n",
    "X.fillna(0.0, inplace=True)\n",
    "\n",
    "#Train test split\n",
    "\n",
    "print('Splitting ...')\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state = RANDOM_SEED, stratify=Y)\n",
    "print('Spliiting done.')\n",
    "del X\n",
    "del Y\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "# Eliminate mutually correlated feature pairs\n",
    "\n",
    "print('Correlated feature elimination')\n",
    "\n",
    "X_train = corr_df(X_train, 1.00)\n",
    "print(X_train.columns)\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "# Scale\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(scaler.transform(X_train))\n",
    "X_test = pd.DataFrame(scaler.transform(X_test))\n",
    "\n",
    "#print('MI classif ...')\n",
    "#mi = np.array(mutual_info_classif(X_train, Y_train, n_neighbors=5, copy=True))\n",
    "#X_train = X_train[X_train.columns[mi.argsort()[-39:][::-1]]]\n",
    "#X_test = X_test[X_test.columns[mi.argsort()[-39:][::-1]]]\n",
    "\n",
    "#print ('Chi Square ...')\n",
    "#chi, _ = np.array(chi2(X_train, Y_train))\n",
    "#X_train = X_train[X_train.columns[chi.argsort()[-35:][::-1]]]\n",
    "#X_test = X_test[X_test.columns[chi.argsort()[-35:][::-1]]]\n",
    "\n",
    "#print('F classif')\n",
    "#chi, _ = np.array(f_classif(X_train, Y_train))\n",
    "#X_train = X_train[X_train.columns[chi.argsort()[-39:][::-1]]]\n",
    "#X_test = X_test[X_test.columns[chi.argsort()[-39:][::-1]]]\n",
    "\n",
    "#feature_indices = np.array([33, 34, 46,  4, 47,  8, 32, 48,  5,  0, 14,  1, 40, 28, 10, 17, 15,\n",
    "#       29, 12, 30, 11, 16,  9, 13,  7, 22,  3, 19, 50, 20,  2, 54, 55, 18,\n",
    "#       21, 51, 53, 23, 31,  6, 49, 37, 38, 52, 35, 24, 44, 45, 42, 41, 36,\n",
    "#       25, 39, 43, 26, 27])\n",
    "#print('Select features')\n",
    "#X_train = X_train[feature_indices[0:25]]\n",
    "#X_test = X_test[feature_indices[0:25]]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a10c074c5afe47b1009769a36d1ec915eed6de700089a4ad8c9756c3e5a59d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
